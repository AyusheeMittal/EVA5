{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eva5 Assignment 6-Regularization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZaxUFh-upV8",
        "colab_type": "text"
      },
      "source": [
        "**Team Members**\n",
        "\n",
        "Avneesh Nolkha\n",
        "\n",
        "Ayushee Mittal\n",
        "\n",
        "Smita Sasindran\n",
        "\n",
        "Vishesh Sethi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pv-t5JpdDS0",
        "colab_type": "text"
      },
      "source": [
        "## **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGRJvQsUc3DC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2GI9sAFdIQJ",
        "colab_type": "text"
      },
      "source": [
        "## **Transforms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX9nSD-C_e2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                      transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz8iGrH0dUxY",
        "colab_type": "text"
      },
      "source": [
        "## **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9UB_t0s_pKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bblr6MqYdXm_",
        "colab_type": "text"
      },
      "source": [
        "## **Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja6Yrcq9_w22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "363ecf89-f708-461e-d71f-44bff6e50b83"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrsymfKpCnXV",
        "colab_type": "text"
      },
      "source": [
        "## **Ghost Batch Normalization classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbF_tA_eCnr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm(nn.BatchNorm2d):\n",
        "    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight=True, bias=True):\n",
        "        super().__init__(num_features, eps=eps, momentum=momentum)\n",
        "        self.weight.data.fill_(1.0)\n",
        "        self.bias.data.fill_(0.0)\n",
        "        self.weight.requires_grad = weight\n",
        "        self.bias.requires_grad = bias\n",
        "\n",
        "\n",
        "class GhostBatchNorm(BatchNorm):\n",
        "    def __init__(self, num_features, num_splits, **kw):\n",
        "        super().__init__(num_features, **kw)\n",
        "        self.num_splits = num_splits\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features * self.num_splits))\n",
        "        self.register_buffer('running_var', torch.ones(num_features * self.num_splits))\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        if (self.training is True) and (mode is False):  # lazily collate stats when we are going to use them\n",
        "            self.running_mean = torch.mean(self.running_mean.view(self.num_splits, self.num_features), dim=0).repeat(\n",
        "                self.num_splits)\n",
        "            self.running_var = torch.mean(self.running_var.view(self.num_splits, self.num_features), dim=0).repeat(\n",
        "                self.num_splits)\n",
        "        return super().train(mode)\n",
        "\n",
        "    def forward(self, input):\n",
        "        N, C, H, W = input.shape\n",
        "        if self.training or not self.track_running_stats:\n",
        "            return F.batch_norm(\n",
        "                input.view(-1, C * self.num_splits, H, W), self.running_mean, self.running_var,\n",
        "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
        "                True, self.momentum, self.eps).view(N, C, H, W)\n",
        "        else:\n",
        "            return F.batch_norm(\n",
        "                input, self.running_mean[:self.num_features], self.running_var[:self.num_features],\n",
        "                self.weight, self.bias, False, self.momentum, self.eps)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io7IDVsvdhVB",
        "colab_type": "text"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8r-6s9mHAPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout_value = 0.09\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, gbn, gbn_split):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.gbn = gbn\n",
        "        self.gbn_split = gbn_split\n",
        "\n",
        "        print(\"Is GBN run:\", gbn)\n",
        "        # Add BatchNorm or GhostBatchNorm\n",
        "        def BNLayer(n_features):\n",
        "            bn = nn.BatchNorm2d(n_features) if not self.gbn else GhostBatchNorm(n_features, self.gbn_split) \n",
        "            return bn\n",
        "\n",
        "\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            #nn.BatchNorm2d(10),\n",
        "            BNLayer(10),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 26\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            #nn.BatchNorm2d(16),\n",
        "            BNLayer(16),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 24\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            #nn.BatchNorm2d(10)\n",
        "            nn.BatchNorm2d(10)\n",
        "        ) # output_size = 24\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            #nn.BatchNorm2d(10),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 10\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=12, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            #nn.BatchNorm2d(12),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            #nn.BatchNorm2d(16),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 6\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=20, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            #nn.BatchNorm2d(20),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 6\n",
        "        \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        ) # output_size = 1\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=20, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(10),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        ) \n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.gap(x)        \n",
        "        x = self.convblock8(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlckNRvDdoD5",
        "colab_type": "text"
      },
      "source": [
        "## **Model Params**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVyKicBtdrEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "c5081f19-b2d9-48aa-c4b0-9f4429805167"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net(False, 1).to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "Is GBN run: False\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 26, 26]              90\n",
            "              ReLU-2           [-1, 10, 26, 26]               0\n",
            "       BatchNorm2d-3           [-1, 10, 26, 26]              20\n",
            "           Dropout-4           [-1, 10, 26, 26]               0\n",
            "            Conv2d-5           [-1, 16, 24, 24]           1,440\n",
            "              ReLU-6           [-1, 16, 24, 24]               0\n",
            "       BatchNorm2d-7           [-1, 16, 24, 24]              32\n",
            "           Dropout-8           [-1, 16, 24, 24]               0\n",
            "            Conv2d-9           [-1, 10, 24, 24]             160\n",
            "             ReLU-10           [-1, 10, 24, 24]               0\n",
            "      BatchNorm2d-11           [-1, 10, 24, 24]              20\n",
            "        MaxPool2d-12           [-1, 10, 12, 12]               0\n",
            "           Conv2d-13           [-1, 10, 10, 10]             900\n",
            "             ReLU-14           [-1, 10, 10, 10]               0\n",
            "      BatchNorm2d-15           [-1, 10, 10, 10]              20\n",
            "          Dropout-16           [-1, 10, 10, 10]               0\n",
            "           Conv2d-17             [-1, 12, 8, 8]           1,080\n",
            "             ReLU-18             [-1, 12, 8, 8]               0\n",
            "      BatchNorm2d-19             [-1, 12, 8, 8]              24\n",
            "          Dropout-20             [-1, 12, 8, 8]               0\n",
            "           Conv2d-21             [-1, 16, 6, 6]           1,728\n",
            "             ReLU-22             [-1, 16, 6, 6]               0\n",
            "      BatchNorm2d-23             [-1, 16, 6, 6]              32\n",
            "          Dropout-24             [-1, 16, 6, 6]               0\n",
            "           Conv2d-25             [-1, 20, 6, 6]           2,880\n",
            "             ReLU-26             [-1, 20, 6, 6]               0\n",
            "      BatchNorm2d-27             [-1, 20, 6, 6]              40\n",
            "          Dropout-28             [-1, 20, 6, 6]               0\n",
            "        AvgPool2d-29             [-1, 20, 1, 1]               0\n",
            "           Conv2d-30             [-1, 10, 1, 1]             200\n",
            "================================================================\n",
            "Total params: 8,666\n",
            "Trainable params: 8,666\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.72\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.76\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZcGpMCrTo_h",
        "colab_type": "text"
      },
      "source": [
        "## **Setting up parameters for 5 runs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWns5AjjTtcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_params = [\n",
        "  {'model': 'L1_with_BN', 'l1': True, 'l2': False, 'gbn': False, 'gbn_split': 1, 'l_l1': 0.0000085},\n",
        "  {'model': 'L2_with_BN', 'l1': False, 'l2': True, 'gbn': False, 'gbn_split': 1, 'l_l1': 0},\n",
        "  {'model': 'L1_and_L2_with_BN', 'l1': True, 'l2': True, 'gbn': False, 'gbn_split': 1, 'l_l1': 0.00000000009},\n",
        "  {'model': 'GBN', 'l1': False, 'l2': False, 'gbn': True, 'gbn_split': 2, 'l_l1': 0},\n",
        "  {'model': 'L1_and_L2_with_GBN', 'l1': True, 'l2': True, 'gbn': True, 'gbn_split': 2, 'l_l1': 0.00000000000001}\n",
        "]\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq3t-rSPp0tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_losses = {}\n",
        "train_acc = {}\n",
        "test_losses = {}\n",
        "test_acc = {}\n",
        "for rp in run_params:\n",
        "  train_losses[rp['model']] = []\n",
        "  train_acc[rp['model']] = []\n",
        "  test_losses[rp['model']] = []\n",
        "  test_acc[rp['model']] = []\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWo5Ny6aduIC",
        "colab_type": "text"
      },
      "source": [
        "## **Training and Testing Loops**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57yWDgg6BBHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# train_losses = []\n",
        "# train_acc = []\n",
        "# test_losses = []\n",
        "# test_acc = []\n",
        "\n",
        "misclassified = []\n",
        "\n",
        "#{'model': 'L1_with_BN', 'l1': True, 'l2': False, 'gbn': False, 'gbn_split': 1},\n",
        "def train(model, device, train_loader, optimizer, epoch, params):\n",
        "  name = params['model']\n",
        "\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader, position=0)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    l1_reg = 0\n",
        "    l2_reg = 0\n",
        "\n",
        "    if params['l1']:\n",
        "      for param in model.parameters():\n",
        "        l1_reg += param.abs().sum()\n",
        "\n",
        "    # if params['l2']:\n",
        "    #   for param in model.parameters():\n",
        "    #     l2_reg += param.norm(2)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target) + params['l_l1'] * l1_reg #+ lambda_l2 * l2_reg\n",
        "\n",
        "    #train_losses.append(loss)\n",
        "    train_losses[name].append(loss)\n",
        "\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    #train_acc.append(100*correct/processed)\n",
        "    train_acc[name].append(100*correct/processed)\n",
        "  \n",
        "\n",
        "def test(model, device, test_loader, params):\n",
        "    name = params['model']\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    #test_losses.append(test_loss)\n",
        "    test_losses[name].append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    #test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "    test_acc[name].append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5HdrVLYT2l5",
        "colab_type": "text"
      },
      "source": [
        "## **Running the models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw0UflFUYSno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50a7ee5f-3844-451d-c7d8-2bd5f3992caa"
      },
      "source": [
        "models = {}\n",
        "\n",
        "optim_params = {\n",
        "  'L1_with_BN':        {'lr':0.025, 'step_size': 12,'gamma': 0.2, 'weight_decay': 0},\n",
        "  'L2_with_BN':        {'lr':0.025, 'step_size': 6, 'gamma': 0.1, 'weight_decay': 0.000095},\n",
        "  'L1_and_L2_with_BN': {'lr':0.025, 'step_size': 6, 'gamma': 0.1, 'weight_decay': 0.000009},\n",
        "  'GBN':               {'lr':0.025, 'step_size': 6, 'gamma': 0.1, 'weight_decay': 0},\n",
        "  'L1_and_L2_with_GBN':{'lr':0.025, 'step_size': 6, 'gamma': 0.1, 'weight_decay': 0.0000001} \n",
        "}\n",
        "\n",
        "\n",
        "for i, rp in enumerate(run_params):\n",
        "    name = rp['model']\n",
        "    opt = optim_params[name]\n",
        "    print(\"\\n\\n ******** Running for: \", name, \"====================================================\")\n",
        "    model =  Net(rp['gbn'], rp['gbn_split']).to(device)\n",
        "    \n",
        "    #optimizer = optim.SGD(model.parameters(), lr=0.0180, momentum=0.92)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=opt['lr'], momentum=0.9, weight_decay=opt['weight_decay'])\n",
        "    scheduler = StepLR(optimizer, step_size=opt['step_size'], gamma=opt['gamma'])\n",
        "\n",
        "    models[name] = model\n",
        "\n",
        "    EPOCHS = 25\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(\"EPOCH:\", epoch+1)\n",
        "        train(model, device, train_loader, optimizer, epoch, rp)\n",
        "        scheduler.step()\n",
        "        test(model, device, test_loader, rp)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " ******** Running for:  L1_with_BN ====================================================\n",
            "Is GBN run: False\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.16970933973789215 Batch_id=468 Accuracy=90.74: 100%|██████████| 469/469 [00:13<00:00, 33.81it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0586, Accuracy: 9832/10000 (98.32%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09658050537109375 Batch_id=468 Accuracy=97.79: 100%|██████████| 469/469 [00:14<00:00, 32.92it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0383, Accuracy: 9883/10000 (98.83%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07129324227571487 Batch_id=468 Accuracy=98.16: 100%|██████████| 469/469 [00:14<00:00, 33.42it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0371, Accuracy: 9890/10000 (98.90%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06221919506788254 Batch_id=468 Accuracy=98.42: 100%|██████████| 469/469 [00:13<00:00, 33.71it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0292, Accuracy: 9906/10000 (99.06%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09831634908914566 Batch_id=468 Accuracy=98.45: 100%|██████████| 469/469 [00:13<00:00, 33.54it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0278, Accuracy: 9907/10000 (99.07%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02460932731628418 Batch_id=468 Accuracy=98.56: 100%|██████████| 469/469 [00:14<00:00, 33.09it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0262, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08888830989599228 Batch_id=468 Accuracy=98.62: 100%|██████████| 469/469 [00:14<00:00, 32.85it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0235, Accuracy: 9920/10000 (99.20%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03465050086379051 Batch_id=468 Accuracy=98.68: 100%|██████████| 469/469 [00:14<00:00, 32.64it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0270, Accuracy: 9922/10000 (99.22%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09611067175865173 Batch_id=468 Accuracy=98.71: 100%|██████████| 469/469 [00:13<00:00, 33.56it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0245, Accuracy: 9920/10000 (99.20%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.012981785461306572 Batch_id=468 Accuracy=98.80: 100%|██████████| 469/469 [00:14<00:00, 33.17it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0276, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08324089646339417 Batch_id=468 Accuracy=98.83: 100%|██████████| 469/469 [00:14<00:00, 33.26it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0236, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02004539966583252 Batch_id=468 Accuracy=98.89: 100%|██████████| 469/469 [00:14<00:00, 33.17it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0217, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0712633728981018 Batch_id=468 Accuracy=99.04: 100%|██████████| 469/469 [00:14<00:00, 32.96it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0195, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01763000339269638 Batch_id=468 Accuracy=99.11: 100%|██████████| 469/469 [00:13<00:00, 33.66it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0180, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "EPOCH: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04764033481478691 Batch_id=468 Accuracy=99.11: 100%|██████████| 469/469 [00:13<00:00, 33.78it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0190, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "EPOCH: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.014264119789004326 Batch_id=468 Accuracy=99.12: 100%|██████████| 469/469 [00:14<00:00, 32.64it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0193, Accuracy: 9939/10000 (99.39%)\n",
            "\n",
            "EPOCH: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02856164239346981 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:14<00:00, 33.14it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0189, Accuracy: 9941/10000 (99.41%)\n",
            "\n",
            "EPOCH: 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.009815159253776073 Batch_id=468 Accuracy=99.16: 100%|██████████| 469/469 [00:14<00:00, 32.50it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0198, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "EPOCH: 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02999270334839821 Batch_id=468 Accuracy=99.16: 100%|██████████| 469/469 [00:13<00:00, 34.14it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0181, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "EPOCH: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02637755125761032 Batch_id=468 Accuracy=99.18: 100%|██████████| 469/469 [00:13<00:00, 33.67it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0197, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "EPOCH: 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.028327669948339462 Batch_id=468 Accuracy=99.12: 100%|██████████| 469/469 [00:14<00:00, 33.15it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0196, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "EPOCH: 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02076868712902069 Batch_id=468 Accuracy=99.16: 100%|██████████| 469/469 [00:14<00:00, 32.17it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0180, Accuracy: 9943/10000 (99.43%)\n",
            "\n",
            "EPOCH: 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01989126205444336 Batch_id=468 Accuracy=99.17: 100%|██████████| 469/469 [00:14<00:00, 32.66it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0165, Accuracy: 9949/10000 (99.49%)\n",
            "\n",
            "EPOCH: 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01745595410466194 Batch_id=468 Accuracy=99.22: 100%|██████████| 469/469 [00:13<00:00, 34.11it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0171, Accuracy: 9950/10000 (99.50%)\n",
            "\n",
            "EPOCH: 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.033173151314258575 Batch_id=468 Accuracy=99.23: 100%|██████████| 469/469 [00:14<00:00, 33.20it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0175, Accuracy: 9946/10000 (99.46%)\n",
            "\n",
            "\n",
            "\n",
            " ******** Running for:  L2_with_BN ====================================================\n",
            "Is GBN run: False\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.19346795976161957 Batch_id=468 Accuracy=90.61: 100%|██████████| 469/469 [00:13<00:00, 34.61it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0626, Accuracy: 9818/10000 (98.18%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07795282453298569 Batch_id=468 Accuracy=97.38: 100%|██████████| 469/469 [00:13<00:00, 35.73it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0485, Accuracy: 9842/10000 (98.42%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.13764148950576782 Batch_id=468 Accuracy=97.96: 100%|██████████| 469/469 [00:13<00:00, 35.52it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0319, Accuracy: 9895/10000 (98.95%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.049399182200431824 Batch_id=468 Accuracy=98.27: 100%|██████████| 469/469 [00:13<00:00, 34.93it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0325, Accuracy: 9893/10000 (98.93%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.034031759947538376 Batch_id=468 Accuracy=98.38: 100%|██████████| 469/469 [00:13<00:00, 34.83it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0286, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03353825584053993 Batch_id=468 Accuracy=98.49: 100%|██████████| 469/469 [00:13<00:00, 34.77it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0276, Accuracy: 9902/10000 (99.02%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02796234004199505 Batch_id=468 Accuracy=98.80: 100%|██████████| 469/469 [00:13<00:00, 34.83it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0205, Accuracy: 9932/10000 (99.32%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03268913924694061 Batch_id=468 Accuracy=98.87: 100%|██████████| 469/469 [00:13<00:00, 35.01it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0186, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04881707951426506 Batch_id=468 Accuracy=98.89: 100%|██████████| 469/469 [00:13<00:00, 35.21it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0195, Accuracy: 9939/10000 (99.39%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.05114399269223213 Batch_id=468 Accuracy=98.88: 100%|██████████| 469/469 [00:13<00:00, 35.55it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0194, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.00981215387582779 Batch_id=468 Accuracy=98.87: 100%|██████████| 469/469 [00:13<00:00, 35.71it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0194, Accuracy: 9941/10000 (99.41%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01965942233800888 Batch_id=175 Accuracy=98.92:  37%|███▋      | 175/469 [00:04<00:08, 36.50it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73zQg2kRHn33",
        "colab_type": "text"
      },
      "source": [
        "## **Plotting functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4u9w-HV6swj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "def plot_with_legends(run_params, data, title):\n",
        "    figure = plt.figure()\n",
        "    #figure.suptitle(title, fontsize=16)\n",
        "    plt.figure(figsize=(15,8))\n",
        "    \n",
        "    for i, pld in enumerate(run_params):\n",
        "        name = pld['model']\n",
        "        plt.plot(data[name], label=name)\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    fname = name + \"_\" + title  \n",
        "    plt.savefig(fname + \".png\")\n",
        "    files.download(fname + \".png\") \n",
        "    plt.show()  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMcA9PTAck82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_with_legends(run_params, train_acc, 'Training Accuracy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0rnAu7WcoT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plot_with_legends(run_params, test_acc, 'Test Accuracy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiIBcKHPgRZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_with_legends(run_params, train_losses, 'Training Loss')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo_8gN0Ucqws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_with_legends(run_params, test_losses, 'Test Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrcLOHlevPp2",
        "colab_type": "text"
      },
      "source": [
        "## **Misclassified Images with GBN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6FpdO6EvFVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbn_model = models['GBN']\n",
        "\n",
        "\n",
        "incorrect_indexes = {} # {23: {'actual': 1, 'predicted': 4}}\n",
        "gbn_model.eval()\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = gbn_model(data)\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "\n",
        "        for sampleno in range(data.shape[0]):\n",
        "                if(target[sampleno]!=pred[sampleno]):\n",
        "                    count += 1\n",
        "                    #print(\"Index=\", sampleno, \", Actual=\", target[sampleno].cpu().numpy(), \", Predicted: \", pred[sampleno].cpu().numpy()[0])\n",
        "                    incorrect_indexes[sampleno] = {'actual': target[sampleno].cpu().numpy(), \n",
        "                                                   'predicted': pred[sampleno].cpu().numpy()[0], \n",
        "                                                   'data': data[sampleno].cpu().numpy()}\n",
        "\n",
        "#print(incorrect_indexes) \n",
        "print(len(incorrect_indexes))\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ08UZXm2BWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "#{23: {'actual': 1, 'predicted': 4}}\n",
        "x = 0\n",
        "y = 0\n",
        "fig, axs = plt.subplots(5, 5, figsize = (15, 15))\n",
        "plt.setp(axs, xticks=[], yticks=[])\n",
        "fig.subplots_adjust(wspace=0.7)\n",
        "images = list(incorrect_indexes.items())[:25]\n",
        "for index, results in images:\n",
        "  #print(index)\n",
        "  img = results['data'] \n",
        "  img = np.squeeze(img)\n",
        "  actual_class = results['actual'] \n",
        "  predicted_class =  results['predicted'] \n",
        "\n",
        "  plt.savefig(\"misclassified.png\")\n",
        "  files.download(\"misclassified.png\")  \n",
        "  axs[x, y].imshow(img)\n",
        "  axs[x, y].set_title('Actual Class:' + str(actual_class) + \"\\nPredicted class: \" + str(predicted_class))\n",
        "  \n",
        "  if y == 4:\n",
        "    x += 1\n",
        "    y = 0\n",
        "  else:\n",
        "    y += 1\n",
        "\n",
        "plt.savefig(\"misclassified.png\")\n",
        "files.download(\"misclassified.png\")     "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}